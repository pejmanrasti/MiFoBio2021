{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pejmanrasti/MiFoBio2021/blob/main/2_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNk9xoejq0Gu"
      },
      "source": [
        "# **Make your fist experience with Tensorflow-Keras**\n",
        "Our goal is to construct and train an artificial neural network on thousands of images of handwritten digits so that it may successfully identify others when presented. The data that will be incorporated is the MNIST database which contains 60,000 images for training and 10,000 test images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUaYe-8hrq0a"
      },
      "source": [
        "## Loading Training and Validation Data\n",
        "\n",
        "The MNIST dataset is conveniently bundled within Keras, and we can easily analyze some of its features in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19s9e7VgHhmR"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.models import Sequential # Model type to be used\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout# Make Fully connected (FC) layers\n",
        "from tensorflow.keras.utils import to_categorical # NumPy related tools\n",
        "from tensorflow.keras.callbacks import TensorBoard  #Visulization of Accuracy and loss\n",
        "\n",
        "\n",
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random                        # for generating random numbers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wTbC_TZbiQw"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIS7BobWfDEK"
      },
      "source": [
        "# **Make a connection between colab and your google drive Where your data are saved.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY_WCus6Vy4l"
      },
      "source": [
        "from google.colab import drive\n",
        "root = '/content/gdrive/'\n",
        "drive.mount( root )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKiPEN9K3L3G"
      },
      "source": [
        "# create permanent directory in gdrive\n",
        "images = r'/My Drive/DIRECTORY OF YOUR OWN DATA/'\n",
        "os.makedirs(root+images, exist_ok=True)\n",
        "os.listdir(root+images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K-UfXaQbvZX"
      },
      "source": [
        "# **Reading and saving data** \n",
        "What we need is a training data directory (and/or validation data directory)  containing one subdirectory per image class, filled with images. For example: \n",
        "\n",
        "```\n",
        "Animals/\n",
        "    train/\n",
        "        dogs/\n",
        "            dog001.jpg\n",
        "            dog002.jpg\n",
        "            ...\n",
        "        cats/\n",
        "            cat001.jpg\n",
        "            cat002.jpg\n",
        "            ...\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n14vJSb4jiB3"
      },
      "source": [
        "DATADIR = root+images\n",
        "CATEGORIES = os.listdir(DATADIR)\n",
        "print(CATEGORIES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyJ-fyinlNlT"
      },
      "source": [
        "training_data = []\n",
        "IMG_SIZE_H=224 # you need to set up a numerical value here. Useful to resize to normalize data size\n",
        "IMG_SIZE_W=224 # you need to set up a numerical value here. Useful to resize to normalize data size\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:\n",
        "\n",
        "        path = os.path.join(DATADIR,category)  # create path to the labels\n",
        "        class_num = CATEGORIES.index(category)  # giving an index to each class (subfolder) -- (0 to the first subfolder, 1 to the first subfolder, etc). \n",
        "\n",
        "        for img in os.listdir(path):  # iterate over each image per psubfolder\n",
        "          if img.endswith('.tif'):\n",
        "            img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)  # convert to array \n",
        "            new_array = cv2.resize(img_array, (IMG_SIZE_H, IMG_SIZE_W))  # resize to normalize data size\n",
        "            training_data.append([new_array, class_num])  # add this to our training_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q74Y7_QzlaGr"
      },
      "source": [
        "create_training_data()  # Calling the function for reading images and labels\n",
        "print(len(training_data)) # Printing the size of the database"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7Oa3lXpSOA"
      },
      "source": [
        "Preparation of data for importing to Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcALEpico-eS"
      },
      "source": [
        "random.shuffle(training_data)\n",
        "X = []  # An Array for images\n",
        "y = []  # An Array for labels\n",
        "\n",
        "for features,label in training_data:   # Seperation of iamegs and labels\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "print(np.array(X).shape) # Print the size of the database"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRyYO9SUpdug"
      },
      "source": [
        "X = np.array(X).reshape(-1, IMG_SIZE_H, IMG_SIZE_W, 1)  # Reshape data in a form that is suitable for keras\n",
        "print(X.shape) # Print the size of the database"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYXc34napn9n"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyugMSBellom"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDJONvqup8Px"
      },
      "source": [
        "# Display 3 images \n",
        "plt.subplot(131)\n",
        "plt.imshow(X[0,:,:,:])\n",
        "plt.axis(\"off\")\n",
        "plt.subplot(132)\n",
        "plt.imshow(X[10,:,:,:])\n",
        "plt.axis(\"off\")\n",
        "plt.subplot(133)\n",
        "plt.imshow(X[30,:,:,:]) \n",
        "plt.axis(\"off\")\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEFL5miLsJAO"
      },
      "source": [
        "# **Importing necessary Libraries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_gM34gjBsAW"
      },
      "source": [
        "# **Let's go furter with introducing CNN**\n",
        "Before, we built a network that accepts the normalized pixel values of each value and operates soley on those values. What if we could instead feed different features (e.g. curvature, edges) of each image into a network, and have the network learn which features are important for classifying an image?\n",
        "\n",
        "This possible through convolution! Convolution applies kernels (filters) that traverse through each image and generate feature maps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HfNFU_ZCV7t"
      },
      "source": [
        "# import some additional tools\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsVz160NDdwF"
      },
      "source": [
        "modelCNN = Sequential([\n",
        "    \n",
        "    # Convolution Layer 1\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)), # 32 different 3x3 kernels -- so 32 feature maps\n",
        "    MaxPooling2D(pool_size=(2, 2)), # Pool the max values over a 2x2 kernel\n",
        "\n",
        "    # Convolution Layer 2\n",
        "    Conv2D(64, (3, 3), activation='relu'), # 64 different 3x3 kernels \n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Convolution Layer 3\n",
        "    Conv2D(128, (3, 3), activation='relu'), # 128 different 3x3 kernels\n",
        "\n",
        "    Flatten(), # Flatten final 7x7x128 output matrix into a 1024-length vector \n",
        "\n",
        "    # Fully Connected Layer 4\n",
        "    Dense(512), # 512 FCN nodes\n",
        "    Activation('relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(10),\n",
        "    Activation('softmax'),\n",
        "])\n",
        "modelCNN.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH9KNpw-FMZP"
      },
      "source": [
        "import datetime\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2kzBiLRE3Hw",
        "scrolled": true
      },
      "source": [
        "modelCNN.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelCNN.fit(X_train, y_train, \n",
        "          validation_data=(X_test, y_test),\n",
        "          epochs=20, batch_size=10,\n",
        "          verbose=1,\n",
        "          callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipCAB6BZMZjh"
      },
      "source": [
        "**Evaluation and Prediction**\n",
        "\n",
        "We can use our model to make a prediction on new images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNFXqmiSOMtp"
      },
      "source": [
        "modelCNN.evaluate(X_test,Y_test,verbose=0) #Evaluation of the model on the test dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Lv4PC_FpaH"
      },
      "source": [
        "modelCNN.predict_classes(X_test,verbose=0) # Prediction of classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-WoRJj5PMlt"
      },
      "source": [
        "# Prediction of classes of a single image\n",
        "img=X_test[1,:,:,:]\n",
        "img = np.array(img).reshape(-1, 224, 224, 1)\n",
        "output = modelCNN.predict_classes(img)\n",
        "print('The predicted label is: ',output[0])\n",
        "print('The real label is: ',y_test[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}